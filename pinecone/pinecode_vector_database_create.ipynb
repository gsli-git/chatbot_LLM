{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Yes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pinecone-client openai langchain PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import json\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdfToPineconeProcessor:\n",
    "    def __init__(self, openai_api_key: str, pinecone_api_key: str, index_name: str):\n",
    "        \"\"\"\n",
    "        Initialize the processor with necessary API keys and configurations.\n",
    "        \n",
    "        Args:\n",
    "            openai_api_key (str): OpenAI API key for generating embeddings\n",
    "            pinecone_api_key (str): Pinecone API key for vector database\n",
    "            index_name (str): Name of the Pinecone index to use\n",
    "        \"\"\"\n",
    "        self.openai_api_key = openai_api_key\n",
    "        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "        self.pc = Pinecone(api_key=pinecone_api_key)\n",
    "        self.index_name = index_name\n",
    "        \n",
    "        # Initialize text splitter with specific parameters\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        )\n",
    "\n",
    "    def create_index_if_not_exists(self, dimension: int = 1536):\n",
    "        \"\"\"\n",
    "        Create a Pinecone index if it doesn't already exist.\n",
    "        \n",
    "        Args:\n",
    "            dimension (int): Dimension of the vectors (1536 for OpenAI embeddings)\n",
    "        \"\"\"\n",
    "        if self.index_name not in self.pc.list_indexes().names():\n",
    "            self.pc.create_index(\n",
    "                name=self.index_name,\n",
    "                dimension=dimension,\n",
    "                metric='cosine',\n",
    "                spec=ServerlessSpec(\n",
    "                    cloud='aws',\n",
    "                    region='us-west-2'\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract text content from a PDF file.\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            \n",
    "        Returns:\n",
    "            str: Extracted text content\n",
    "        \"\"\"\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Split text into smaller chunks for processing.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text to split\n",
    "            \n",
    "        Returns:\n",
    "            List[str]: List of text chunks\n",
    "        \"\"\"\n",
    "        return self.text_splitter.split_text(text)\n",
    "\n",
    "    def generate_document_metadata(self, pdf_path: str) -> dict:\n",
    "        \"\"\"\n",
    "        Generate metadata for the document.\n",
    "        \n",
    "        Args:\n",
    "            pdf_path (str): Path to the PDF file\n",
    "            \n",
    "        Returns:\n",
    "            dict: Document metadata\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"source\": os.path.basename(pdf_path),\n",
    "            \"file_path\": pdf_path,\n",
    "            \"type\": \"pdf\"\n",
    "        }\n",
    "\n",
    "    def process_and_upload(self, pdf_paths: List[str]):\n",
    "        \"\"\"\n",
    "        Process PDFs and upload their embeddings to Pinecone.\n",
    "        \n",
    "        Args:\n",
    "            pdf_paths (List[str]): List of paths to PDF files\n",
    "        \"\"\"\n",
    "        # Ensure index exists\n",
    "        self.create_index_if_not_exists()\n",
    "        index = self.pc.Index(self.index_name)\n",
    "        \n",
    "        for pdf_path in pdf_paths:\n",
    "            # Extract text from PDF\n",
    "            text = self.extract_text_from_pdf(pdf_path)\n",
    "            chunks = self.split_text(text)\n",
    "            \n",
    "            # Generate metadata\n",
    "            doc_metadata = self.generate_document_metadata(pdf_path)\n",
    "            \n",
    "            # Process chunks and upload to Pinecone\n",
    "            vectors_to_upsert = []\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                # Generate embeddings\n",
    "                embedding = self.embeddings.embed_query(chunk)\n",
    "                \n",
    "                # Create a unique ID for the chunk\n",
    "                chunk_id = hashlib.md5(f\"{pdf_path}_{i}\".encode()).hexdigest()\n",
    "                \n",
    "                # Combine document metadata with chunk-specific metadata\n",
    "                metadata = {\n",
    "                    **doc_metadata,\n",
    "                    \"chunk_index\": i,\n",
    "                    \"text\": chunk\n",
    "                }\n",
    "                \n",
    "                vectors_to_upsert.append({\n",
    "                    \"id\": chunk_id,\n",
    "                    \"values\": embedding,\n",
    "                    \"metadata\": metadata\n",
    "                })\n",
    "                \n",
    "                # Batch upload in groups of 100\n",
    "                if len(vectors_to_upsert) >= 100:\n",
    "                    index.upsert(vectors=vectors_to_upsert)\n",
    "                    vectors_to_upsert = []\n",
    "            \n",
    "            # Upload any remaining vectors\n",
    "            if vectors_to_upsert:\n",
    "                index.upsert(vectors=vectors_to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "open_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open_api_key[:25])\n",
    "print(pinecone_api_key[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = PdfToPineconeProcessor(\n",
    "    openai_api_key=open_api_key,\n",
    "    pinecone_api_key=pinecone_api_key,\n",
    "    # index_name=\"research-papers\"\n",
    "    index_name=\"research-paper-on-vehicle-rag-index\"\n",
    ")\n",
    "\n",
    "pdf_paths = [\"./paper/2023_IDETC_paper_Final_v2.pdf\", \"./paper/s00158-023-03553-5.pdf\"]\n",
    "processor.process_and_upload(pdf_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
